{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from groq import Groq\n",
    "\n",
    "from fastmcp.client import Client\n",
    "from mcp.types import Tool\n",
    "\n",
    "\n",
    "def transform_schema_to_parameters(schema: dict) -> dict:\n",
    "    properties = {}\n",
    "    \n",
    "    if schema.get('properties'):\n",
    "        for field_name, field_info in schema['properties'].items():\n",
    "            properties[field_name] = {\n",
    "                \"type\": field_info['type'],\n",
    "                \"description\": field_info['title']\n",
    "            }\n",
    "            # Add default value if it exists\n",
    "            if 'default' in field_info:\n",
    "                properties[field_name]['default'] = field_info['default']\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": properties,\n",
    "        \"required\": schema.get('required')\n",
    "    }\n",
    "    \n",
    "def transform_tool_definition(tool: Tool) -> dict:\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool.name,\n",
    "            \"description\": tool.description,\n",
    "            \"parameters\": transform_schema_to_parameters(tool.inputSchema)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client = Client(\"http://127.0.0.1:8000/mcp\")\n",
    "groq_client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='process_video' description='Process a video file and prepare it for searching.' inputSchema={'properties': {'video_path': {'title': 'Video Path', 'type': 'string'}}, 'required': ['video_path'], 'type': 'object'} annotations=None\n",
      "name='list_tables' description='List all processed videos in the database.' inputSchema={'properties': {}, 'type': 'object'} annotations=None\n",
      "name='get_clip_by_speech_sim' description='Get a video clip based on a user query using the transcripts index.' inputSchema={'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'user_query': {'title': 'User Query', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'user_query'], 'type': 'object'} annotations=None\n",
      "name='get_clip_by_image_sim' description='Get a video clip based on a user query using the image index.' inputSchema={'$defs': {'Base64ToPILImageModel': {'properties': {'image': {'title': 'Image', 'type': 'string'}}, 'required': ['image'], 'title': 'Base64ToPILImageModel', 'type': 'object'}}, 'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'image_base64': {'$ref': '#/$defs/Base64ToPILImageModel', 'title': 'Image Base64'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'image_base64'], 'type': 'object'} annotations=None\n",
      "name='get_clip_by_caption_sim' description='Get a video clip based on a user query using the caption index.' inputSchema={'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'user_query': {'title': 'User Query', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'user_query'], 'type': 'object'} annotations=None\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    tools = await mcp_client.list_tools()\n",
    "    for tool in tools:\n",
    "        print(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_clip_by_caption_sim'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get a video clip based on a user query using the caption index.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'user_query': {'title': 'User Query', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'user_query'], 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "print(tool.inputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'object',\n",
       " 'properties': {'video_name': {'type': 'string', 'description': 'Video Name'},\n",
       "  'user_query': {'type': 'string', 'description': 'User Query'},\n",
       "  'top_k': {'type': 'integer', 'description': 'Top K', 'default': 3}},\n",
       " 'required': ['video_name', 'user_query']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_schema_to_parameters(tool.inputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client:\n",
    "    mcp_tools = await mcp_client.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='process_video', description='Process a video file and prepare it for searching.', inputSchema={'properties': {'video_path': {'title': 'Video Path', 'type': 'string'}}, 'required': ['video_path'], 'type': 'object'}, annotations=None),\n",
       " Tool(name='list_tables', description='List all processed videos in the database.', inputSchema={'properties': {}, 'type': 'object'}, annotations=None),\n",
       " Tool(name='get_clip_by_speech_sim', description='Get a video clip based on a user query using the transcripts index.', inputSchema={'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'user_query': {'title': 'User Query', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'user_query'], 'type': 'object'}, annotations=None),\n",
       " Tool(name='get_clip_by_image_sim', description='Get a video clip based on a user query using the image index.', inputSchema={'$defs': {'Base64ToPILImageModel': {'properties': {'image': {'title': 'Image', 'type': 'string'}}, 'required': ['image'], 'title': 'Base64ToPILImageModel', 'type': 'object'}}, 'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'image_base64': {'$ref': '#/$defs/Base64ToPILImageModel', 'title': 'Image Base64'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'image_base64'], 'type': 'object'}, annotations=None),\n",
       " Tool(name='get_clip_by_caption_sim', description='Get a video clip based on a user query using the caption index.', inputSchema={'properties': {'video_name': {'title': 'Video Name', 'type': 'string'}, 'user_query': {'title': 'User Query', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['video_name', 'user_query'], 'type': 'object'}, annotations=None)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [transform_tool_definition(mcp_tools[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = 'llama-3.3-70b-versatile'\n",
    "USER_PROMPT = \"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a video processing assistant. You need to find videoclips using the tool `find_videoclip` or answer general questions about the video using the `get_video_information` tool\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hey! What's your name?\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = groq_client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    stream=False,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    max_completion_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have a personal name, but I'm here to help you with video processing tasks. How can I assist you today? Do you need help finding a specific video clip or would you like to know more about a particular video?\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What's the weather like in San Francisco?\n",
      "Tool: get_weather_info\n",
      "Parameters: {\"location\": \"San Francisco\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'llama-3.3-70b-versatile'\n",
    "\n",
    "# Define the tool schema\n",
    "tool_schema = {\n",
    "    \"name\": \"get_weather_info\",\n",
    "    \"description\": \"Get the weather information for any location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The location for which we want to get the weather information (e.g., New York)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the Pydantic model for the tool call\n",
    "class ToolCall(BaseModel):\n",
    "    input_text: str = Field(description=\"The user's input text\")\n",
    "    tool_name: str = Field(description=\"The name of the tool to call\")\n",
    "    tool_parameters: str = Field(description=\"JSON string of tool parameters\")\n",
    "\n",
    "class ResponseModel(BaseModel):\n",
    "    tool_calls: list[ToolCall]\n",
    "\n",
    "# Patch Groq() with instructor\n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)\n",
    "\n",
    "def run_conversation(user_prompt):\n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are an assistant that can use tools. You have access to the following tool: {tool_schema}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Make the Groq API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        response_model=ResponseModel,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_completion_tokens=1000,\n",
    "    )\n",
    "\n",
    "    return response.tool_calls\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What's the weather like in San Francisco?\"\n",
    "tool_calls = run_conversation(user_prompt)\n",
    "\n",
    "for call in tool_calls:\n",
    "    print(f\"Input: {call.input_text}\")\n",
    "    print(f\"Tool: {call.tool_name}\")\n",
    "    print(f\"Parameters: {call.tool_parameters}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
